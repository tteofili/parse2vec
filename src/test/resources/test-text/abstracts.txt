A calculus which combined the flexible geometric structure of vector models with the crisp efficiency of Boolean logic would be extremely beneficial for modelling natural language .
With this goal in mind , we present a formulation for logical connectives in vector spaces based on standard linear algebra , giving examples of the use of vector negation to discriminate between different senses of ambiguous words .
It turns out that the operators developed in this way are precisely the connectives of quantum logic ( Birkhoff and von Neumann , 1936 ) , which to our knowledge have not been exploited before in natural language processing .
In quantum logic , arbitrary sets are replaced by linear subspaces of a vector space , and set unions , intersections and complements are replaced by vector sum , intersection and orthogonal complements of subspaces .
We demonstrate that these logical connectives ( particularly the orthogonal complement for negation )  are powerful tools for exploring and analysing word meanings and show distinct advantages over Boolean operators in document retrieval experiments .
This paper is organised as follows :
In Section 1.1 we describe some of the ways vectors have been used to represent the meanings of terms and documents in natural language processing , and describe the way the WORD-SPACE used in our later experiments is built automatically from text corpora .
In Section 1.2 we define the logical connectives on vector spaces , focussing particularly on negation and disjunction . 
This introduces the basic material needed to understand the worked examples given in Section 1.3 , and the document retrieval experiments described in Section 1.3.1 .
Section 1.4 gives a much fuller outline of the theory of quantum logic , the natural setting for the operators of Section 1.2 .
Finally , in Section 1.5 , we examine the similarities between quantum logic and WORD-SPACE , asking whether quantum logic is an appropriate framework for modelling word-meanings or if the initial successes we have obtained are mainly coincidental . 
To some extent , this paper may have been written backwards , in that the implementation and examples are at the beginning and most of the theory is at the end .
This is for two reasons :
Firstly , we hoped to make the paper as accessible as possible and were afraid that beginning with an introduction to the full machinery of quantum logic would defeat this goal before the reader has a chance to realise that the techniques and equations used in this work are really quite elementary .
Secondly , the link with ‘quantum logic’ was itself only brought to our attention after the bulk of the results in this paper had been obtained , and since this research is very much ongoing , we deemed it appropriate to give an honest account of its history and current state . 
We propose two novel model architectures for computing continuous vector representations of words from very large data sets The quality of these representations is measured in a word similarity task , and the results are compared to the previously best performing techniques based on different types of neural networks .
We observe large improvements in accuracy at much lower computational cost , i . e  it takes less than a day to learn high quality word vectors from a 1.6 billion words data set .
Furthermore , we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities . 
Information Retrieval ( IR)  models need to deal with two difficult issues , vocabulary mismatch and term dependencies .
Vocabulary mismatch corresponds to the difficulty of retrieving relevant documents that do not contain exact query terms but semantically related terms .
Term dependencies refers to the need of considering the relationship between the words of the query when estimating the relevance of a document .
A multitude of solutions has been proposed to solve each of these two problems , but no principled model solve both .
In parallel , in the last few years , language models based on neural networks have been used to cope with complex natural language processing tasks like emotion and paraphrase detection .
Although they present good abilities to cope with both term dependencies and vocabulary mismatch problems , thanks to the distributed representation of words they are based upon , such models could not be used readily in IR , where the estimation of one language model per document ( or query)  is required .
This is both computationally unfeasible and prone to over-fitting .
Based on a recent work that proposed to learn a generic language model that can be modified through a set of document-specific parameters , we explore use of new neural network models that are adapted to ad-hoc IR tasks .
Within the language model IR framework , we propose and study the use of a generic language model as well as a document-specific language model .
Both can be used as a smoothing component , but the latter is more adapted to the document at hand and has the potential of being used as a full document language model .
We experiment with such models and analyze their results on TREC-1 to 8 datasets .
Bidirectional Long Short-Term Memory Recurrent Neural Network ( BLSTM-RNN ) has been shown to be very effective for modeling and predicting sequential data , e.g. speech utterances or handwritten documents .
In this study , we propose to use BLSTM-RNN for a unified tagging solution that can be applied to various tagging tasks including partof-speech tagging , chunking and named entity recognition .
Instead of exploiting specific features carefully optimized for each task , our solution only uses one set of task-independent features and internal representations learnt from unlabeled text for all tasks .
Requiring no task specific knowledge or sophisticated feature engineering , our approach gets nearly state-ofthe-art performance in all these three tagging tasks .
The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships .
In this paper we present several extensions that improve both the quality of the vectors and the training speed .
By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations .
We also describe a simple alternative to the hierarchical softmax called negative sampling .
An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases .
For example , the meanings of “Canada” and “Air” cannot be easily combined to obtain “Air Canada” .
Motivated by this example , we present a simple method for finding phrases in text , and show that learning good vector representations for millions of phrases is possible .
We extend the word2vec framework to capture meaning across languages .
The input consists of a source text and a word-aligned parallel text in a second language .
The joint word2vec tool then represents words in both languages within a common “semantic” vector space .
The result can be used to enrich lexicons of under-resourced languages , to identify ambiguities , and to perform clustering and classification .
Experiments were conducted on a parallel English-Arabic corpus , as well as on English and Hebrew Biblical texts .
Unsupervised vector-based approaches to semantics can model rich lexical meanings , but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks .
We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semantic term–document information as well as rich sentiment content .
The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations .
We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents ( e.g. star ratings ) .
We evaluate the model using small , widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification .
We also introduce a large dataset of movie reviews to serve as a more robust benchmark for work in this area .
We report our participation in the contextual suggestion track of TREC 2014 for which we submitted two runs using a novel approach to complete the competition .
The goal of the track is to generate suggestions that users might fond of given the history of users’ preference where he or she used to live in when they travel to a new city .
We tested our new approach in the dataset of ClueWeb12-CatB which has been pre-indexed by Lucene .
Our system represents all attractions and user contexts in the continuous vector space learnt by neural network language models , and then we learn the user-dependent profile model to predict the user’s ratings for the attraction’s websites using Softmax .
Finally , we rank all the venues by using the generated model according the users’ personal preference .
We present a comprehensive study of evaluation methods for unsupervised embedding techniques that obtain meaningful representations of words from text .
Different evaluations result in different orderings of embedding methods , calling into question the common assumption that there is one single optimal vector representation .
We present new evaluation techniques that directly compare embeddings with respect to specific queries .
These methods reduce bias , provide greater insight , and allow us to solicit data-driven relevance judgments rapidly and accurately through crowdsourcing .
Continuous word and phrase vectors have proven useful in a number of NLP tasks .
Here we describe our experience using them as a source of features for the SemEval-2015 task 3 , consisting of two community question answering subtasks : Answer Selection for categorizing answers as potential , good , and bad with regards to their corresponding questions ; and YES/NO inference for predicting a yes , no , or unsure response to a YES/NO question using all of its good answers .
Our system ranked 6th and 1st in the English answer selection and YES/NO inference subtasks respectively , and 2nd in the Arabic answer selection subtask .
The word2vec model and application by Mikolov et al. have attracted a great amount of attention in recent two years .
The vector representations of words learned by word2vec models have been proven to be able to carry semantic meanings and are useful in various NLP tasks .
As an increasing number of researchers would like to experiment with word2vec , I notice that there lacks a material that comprehensively explains the parameter learning process of word2vec in details , thus preventing many people with less neural network experience from understanding how exactly word2vec works .
This note provides detailed derivations and explanations of the parameter update equations for the word2vec models , including the original continuous bag-of-word ( CBOW ) and skip-gram models , as well as advanced tricks , hierarchical soft-max and negative sampling .
In the appendix a review is given on the basics of neuron network models and backpropagation .
Over the past few years , neural networks have re-emerged as powerful machine-learning models , yielding state-of-the-art results in fields such as image recognition and speech processing .
More recently , neural network models started to be applied also to textual natural language signals , again with very promising results .
This tutorial surveys neural network models from the perspective of natural language processing research , in an attempt to bring natural-language researchers up to speed with the neural techniques .
The tutorial covers input encoding for natural language tasks , feed-forward networks , convolutional networks , recurrent networks and recursive networks , as well as the computation graph abstraction for automatic gradient computation.
The development of intelligent machines is one of the biggest unsolved challenges in computer science .
In this paper , we propose some fundamental properties these machines should have , focusing in particular on communication and learning .
We discuss a simple environment that could be used to incrementally teach a machine the basics of natural-language-based communication , as a prerequisite to more complex interaction with human users .
We also present some conjectures on the sort of algorithms the machine should support in order to profitably learn from the environment .
In this work , we present the first results for neuralizing an Unsupervised Hidden Markov Model .
We evaluate our approach on tag induction .
Our approach outperforms existing generative models and is competitive with the state-of-the-art though with a simpler model easily extended to include additional context .
Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks .
Although DNNs work well whenever large labeled training sets are available , they cannot be used to map sequences to sequences .
In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure .
Our method uses a multilayered Long Short-TermMemory (LSTM) to map the input sequence to a vector of a fixed dimensionality , and then another deep LSTM to decode the target sequence from the vector .
Our main result is that on an English to French translation task fromtheWMT’14 dataset , the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM’s BLEU score was penalized on out-of-vocabulary words .
Additionally , the LSTM did not have difficulty on long sentences . For comparison , a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset .
When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system , its BLEU score increases to 36.5 , which is close to the previous best result on this task.
The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice.
Finally , we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM’s performancemarkedly , because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier .
We combine Riemannian geometry with the mean field theory of high dimensional chaos to study the nature of signal propagation in generic , deep neural networks with random weights .
Our results reveal an order-to-chaos expressivity phase transition , with networks in the chaotic phase computing nonlinear functions whose global curvature grows exponentially with depth but not width .
We prove this generic class of deep random functions cannot be efficiently computed by any shallow network , going beyond prior work restricted to the analysis of single functions .
Moreover , we formalize and quantitatively demonstrate the long conjectured idea that deep networks can disentangle highly curved manifolds in input space into flat manifolds in hidden space .
Our theoretical analysis of the expressive power of deep networks broadly applies to arbitrary nonlinearities , and provides a quantitative underpinning for previously abstract notions about the geometry of deep functions .
In this paper , we propose a novel neural network model called RNN Encoder–Decoder that consists of two recurrent neural networks (RNN) .
One RNN encodes a sequence of symbols into a fixedlength vector representation , and the other decodes the representation into another sequence of symbols .
The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence .
The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder–Decoder as an additional feature in the existing log-linear model .
Qualitatively , we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases .
Time series often have a temporal hierarchy , with information that is spread out over multiple time scales .
Common recurrent neural networks , however, do not explicitly accommodate such a hierarchy , and most research on them has been focusing on training algorithms rather than on their basic architecture .
In this paper we study the effect of a hierarchy of recurrent neural networks on processing time series .
Here , each layer is a recurrent network which receives the hidden state of the previous layer as input .
This architecture allows us to perform hierarchical processing on difficult temporal tasks , and more naturally capture the structure of time series .
We show that they reach state-of-the-art performance for recurrent networks in character-level language modeling when trained with simple stochastic gradient descent .
We also offer an analysis of the different emergent time scales .
In this paper , we explore different ways to extend a recurrent neural network (RNN) to a deep RNN .
We start by arguing that the concept of depth in an RNN is not as clear as it is in feedforward neural networks .
By carefully analyzing and understanding the architecture of an RNN , however , we find three points of an RNN which may be made deeper ; (1) input-to-hidden function , (2) hidden-tohidden transition and (3) hidden-to-output function .
Based on this observation , we propose two novel architectures of a deep RNN which are orthogonal to an earlier attempt of stacking multiple recurrent layers to build a deep RNN (Schmidhuber , 1992; El Hihi and Bengio , 1996) .
We provide an alternative interpretation of these deep RNNs using a novel framework based on neural operators .
The proposed deep RNNs are empirically evaluated on the tasks of polyphonic music prediction and language modeling .
The experimental result supports our claim that the proposed deep RNNs benefit from the depth and outperform the conventional , shallow RNNs.
Reasoning and inference are central to human and artificial intelligence .
Modeling inference in human language is notoriously challenging but is fundamental to natural language understanding and many applications .
With the availability of large annotated data , neural network models have recently advanced the field significantly .
In this paper , we present a new state-of-the-art result , achieving the accuracy of 88.3% on the standard benchmark , the Stanford Natural Language Inference dataset .
This result is achieved first through our enhanced sequential encoding model , which outperforms the previous best model that employs more complicated network architectures , suggesting that the potential of sequential LSTM-based models have not been fully explored yet in previous work .
We further show that by explicitly considering recursive architectures , we achieve additional improvement .
Particularly , incorporating syntactic parse information contributes to our best result ; it improves the performance even when the parse information is added to an already very strong system .
We present a neural architecture for sequence processing .
The ByteNet is a stack of two dilated convolutional neural networks , one to encode the source sequence and one to decode the target sequence , where the target network unfolds dynamically to generate variable length outputs .
The ByteNet has two core properties : it runs in time that is linear in the length of the sequences and it preserves the sequences’ temporal resolution .
The ByteNet decoder attains state-of-the-art performance on character-level language modelling and outperforms the previous best results obtained with recurrent neural networks .
The ByteNet also achieves a performance on raw character-level machine translation that approaches that of the best neural translation models that run in quadratic time .
The implicit structure learnt by the ByteNet mirrors the expected alignments between the sequences .
The Teacher Forcing algorithm trains recurrent networks by supplying observed sequence values as inputs during training and using the network’s own one-stepahead predictions to do multi-step sampling .
We introduce the Professor Forcing algorithm , which uses adversarial domain adaptation to encourage the dynamics of the recurrent network to be the same when training the network and when sampling from the network over multiple time steps .
We apply Professor Forcing to language modeling , vocal synthesis on raw waveforms , handwriting generation , and image generation .
Empirically we find that Professor Forcing acts as a regularizer , improving test likelihood on character level Penn Treebank and sequential MNIST .
We also find that the model qualitatively improves samples , especially when sampling for a large number of time steps .
This is supported by human evaluation of sample quality .
Trade-offs between Professor Forcing and Scheduled Sampling are discussed .
We produce T-SNEs showing that Professor Forcing successfully makes the dynamics of the network during training and sampling more similar .
Most existing machine translation systems operate at the level of words , relying on explicit segmentation to extract tokens .
We introduce a neural machine translation (NMT) model that maps a source character sequence to a target character sequence without any segmentation .
We employ a character-level convolutional network with max-pooling at the encoder to reduce the length of source representation , allowing the model to be trained at a speed comparable to subword-level models while capturing local regularities .
Our character-to-character model outperforms a recently proposed baseline with a subwordlevel encoder on WMT’15 DE-EN and CSEN , and gives comparable performance on FIEN and RU-EN .
We then demonstrate that it is possible to share a single characterlevel encoder across multiple languages by training a model on a many-to-one translation task .
In this multilingual setting , the character-level encoder significantly outperforms the subword-level encoder on all the language pairs .
We observe that on CS-EN , FI-EN and RU-EN , the quality of the multilingual character-level translation even surpasses the models specifically trained on that language pair alone , both in terms of BLEU score and human judgment .
The Teacher Forcing algorithm trains recurrent networks by supplying observed sequence values as inputs during training and using the network’s own one-step- ahead predictions to do multi-step sampling .
We introduce the Professor Forcing algorithm , which uses adversarial domain adaptation to encourage the dynamics of the recurrent network to be the same when training the network and when sampling from the network over multiple time steps .
We apply Professor Forcing to language modeling , vocal synthesis on raw waveforms , handwriting generation , and image generation .
Empirically we find that Professor Forcing acts as a regularizer , improving test likelihood on character level Penn Treebank and sequential MNIST. We also find that the model qualitatively improves samples, especially when sam- pling for a large number of time steps. This is supported by human evaluation of sample quality. Trade-offs between Professor Forcing and Scheduled Sampling are discussed. We produce T-SNEs showing that Professor Forcing successfully makes the dynamics of the network during training and sampling more similar.